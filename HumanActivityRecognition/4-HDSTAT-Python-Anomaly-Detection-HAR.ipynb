{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   [Apprentissage en Grande Dimension](https://github.com/wikistat/High-Dimensional-Learning ):  [Reconnaissance d'Activité Humaine](https://github.com/wikistat/High-Dimensional-Statistics/tree/master/HumanActivityRecognition) ([*HAR*](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>    Detection d'anomalies\n",
    "\n",
    "Ce notebook présente la partie détection d'anomalies sur les signaux bruts. \n",
    "## Objectifs : \n",
    "\n",
    "-Appliquer différentes méthodes de détection d'anomalies sur des données vectorielles : \n",
    "\n",
    "  - Classification ascendante hiérarchique\n",
    "  - One-class SVM\n",
    "  - Local Outlier Factor\n",
    "  - Isolation Forest\n",
    " \n",
    "-Détection d'anomalies sur des données fonctionnelles : transformation des données fonctionnelles afin de définir des caractéristiques (ACP, transformation en ondelettes, FFT) sur lesquelles on applique les méthodes de détection d'anomalies \n",
    "\n",
    "-Comparaison des différentes méthodes  sur les données HAR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ACP\n",
    "import sklearn.decomposition as sd\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "# Hierarchical clustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "# LOF\n",
    "import sklearn.neighbors as sn\n",
    "# Isolation Forest\n",
    "import sklearn.ensemble as se\n",
    "\n",
    "# Plot et Display\n",
    "import utils.illustration as uil\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\"]\n",
    "CMAP = plt.get_cmap(\"Set1\")\n",
    "ACTIVITY_DIC = {1 : \"WALKING\",\n",
    "2 : \"WALKING UP\",\n",
    "3 : \"WALKING DOWN\",\n",
    "4 : \"SITTING\",\n",
    "5 : \"STANDING\",\n",
    "6 : \"LAYING\"}\n",
    "COLOR_DIC = {v:CMAP(k-2) if v!=\"WALKING\" else CMAP(10) for k,v in ACTIVITY_DIC.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données\n",
    "### Téléchargement des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils.load as ul\n",
    "\n",
    "#Multidimensional Data\n",
    "X_train = ul.load_signals(\"train\", SIGNALS)\n",
    "Y_train_label = ul.load_y(\"train\")\n",
    "X_train_metier= ul.my_read_csv(\"train/X_train.txt\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constitution des jeux de données avec anomalies\n",
    "\n",
    "On construit un jeu de données constitué de \n",
    "\n",
    "   * `N_normal` signaux considérés comme normaux (associés au comportement *WALKING*).  \n",
    "   * `N_anormal` signaux par type de signaux anormaux (*SITTING*, *STANDING*, *LAYING*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "N_normal = 800\n",
    "N_anormal = 2\n",
    "\n",
    "# New Y Label\n",
    "Y= np.hstack([np.repeat(1,N_normal)] + [np.repeat(i, N_anormal) for i in range(2,7)])\n",
    "Y_label = np.array([ACTIVITY_DIC[y] for y in Y])\n",
    "#New X Data\n",
    "index_per_act = np.hstack([np.where(Y_train_label==1)[0][:N_normal]] + [np.where(Y_train_label==act)[0][:N_anormal] for act in range(2,7)])\n",
    "\n",
    "X = X_train[index_per_act]\n",
    "X_metier = X_train_metier[index_per_act]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque type de signal, on affiche un echantillon des comportement normaux, ainsi que les différentes anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sample_per_activity = dict([(v,50) if v==\"WALKING\" else (v,N_anormal) for k,v in ACTIVITY_DIC.items()])\n",
    "linestyle_per_activity = dict([(v,\"dashed\") if v==\"WALKING\" else (v,\"solid\") for k,v in ACTIVITY_DIC.items()])\n",
    "linewidth_per_activity = dict([(v,1) if v==\"WALKING\" else (v,2) for k,v in ACTIVITY_DIC.items()])\n",
    "\n",
    "fig = plt.figure(figsize=(16,18))    \n",
    "uil.plot_signaux(fig, X, Y_label, SIGNALS, COLOR_DIC, nb_sample_per_activity, \n",
    "             linestyle_per_activity, linewidth_per_activity, figdim1 = 3, figdim2 = 2, legend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en composantes principales\n",
    "###  Sur un signal : l'accélération en x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "print(\"ACP on signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n",
    "acp = sd.PCA()\n",
    "X_acp_signal = acp.fit_transform(sp.scale(X_signal))\n",
    "\n",
    "X_signal.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = X.shape[0]\n",
    "colors=[COLOR_DIC[y] for y in Y_label]\n",
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_signal, acp, colors=colors, markersizes = markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sur tous les signaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_signaux = np.vstack([x.reshape(128*6) for x in X])\n",
    "acp = sd.PCA()\n",
    "X_acp_signaux = acp.fit_transform(sp.scale(X_signaux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_signaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_signaux, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur les données métiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_metier = acp.fit_transform(sp.scale(X_metier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_metier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_metier, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection d'anomalies sur les données métiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Ascendante Hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(X_metier, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(X_metier)\n",
    "pred = OCS.predict(X_metier)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_svm,COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_metier)\n",
    "\n",
    "CT_metier_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_metier_lof.pred, CT_metier_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_metier_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(X_metier)\n",
    "y_pred = clf.predict(X_metier)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_IF, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q. ** Quelle est votre conclusion sur les données métier ? \n",
    "\n",
    "L'objectif de la section suivant est d'essayer de détecter les anomalies sur les signaux bruts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection d'anomalies sur les signaux bruts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Ascendante Hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(X_signal,'single')\n",
    "\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Combien d anomalies a-t-on détecté ? Obtient-on de meilleurs résultats en prenant tous les signaux ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur les deux premières composantes de l'ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.01)\n",
    "\n",
    "OCS.fit(X_acp_signal[:,:2])\n",
    "pred = OCS.predict(X_acp_signal[:,:2])\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Commentez les résultats. Obtient-on de meilleurs résultats en augmentant le nombre de composantes ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "nu = 0.02\n",
    "\n",
    "# fit the model\n",
    "clf = ssvm.OneClassSVM(kernel=\"rbf\",nu=nu)\n",
    "clf.fit(X_acp[:,:2])\n",
    "y_pred_train = clf.predict(X_acp[:,:2])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "markersizes = [10 if y==1 else 20 for y in Y]\n",
    "labels = [\"\"] * N \n",
    "for il, l in [(np.where(Y_label==y)[0][0],y) for y in set(Y_label)]:\n",
    "    labels[il] = l\n",
    "\n",
    "uil.plot_decision_function(fig, ax, clf, X_acp, y_pred_train, colors=colors, labels = labels, markersizes=markersizes)\n",
    "ax.set_title(\"Novelty Detection : nu=%.1f\" %nu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_svm, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur les signaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(X_signal)\n",
    "pred = OCS.predict(X_signal)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Commenter les résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur un signal : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_signal)\n",
    "\n",
    "CT_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_lof.pred, CT_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(X_signaux)\n",
    "\n",
    "CT_tous_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_tous_lof.pred, CT_tous_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Commenter les résultats. Obtient-on de meilleures performances sur l'ensemble des signaux ? En modifiant les paramètres ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur les composantes de l'ACP : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "n_neighbors = 15\n",
    "\n",
    "# fit the model\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric = metric)\n",
    "y_pred = clf.fit_predict(X_acp[:,:2])\n",
    "\n",
    "CT_ACP_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_lof.pred, CT_ACP_lof.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_decision_function(fig, ax, clf, X_acp, y_pred, method_name=\"LOF\", colors=colors, labels = labels, markersizes=markersizes)\n",
    "ax.set_title(\"Number of neighbors : %d\" %n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur un signal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "#clf.fit(X_acp_metier)\n",
    "#y_pred = clf.predict(X_acp_metier)\n",
    "\n",
    "clf.fit(X_signal)\n",
    "y_pred = clf.predict(X_signaux)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_IF, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur les composantes de l'ACP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_acp = X_acp_signal\n",
    "\n",
    "contamination=0.05\n",
    "clf = se.IsolationForest(n_estimators=100, contamination=contamination, bootstrap=True, n_jobs=-1)\n",
    "clf.fit(X_acp[:,:2])\n",
    "y_pred = clf.predict(X_acp[:,:2])\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats en augmentant le nombre de composantes de l'ACP ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "En conclusion, les méthodes de détection d'anomalies appliquées directement sur les signaux ne fonctionnent pas bien. Nous allons voir si la projection sur une base d'ondelettes permet d'obtenir de meilleurs résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection d'anomalies sur la décomposition en ondelettes  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Décomposition en ondelettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "\n",
    "from statsmodels.robust import mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isignal = 0\n",
    "print(\" signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(wavedec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wf = \"haar\"\n",
    "\n",
    "Coeff = []\n",
    "TCoeff = []\n",
    "for x in X_signal :\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs = pywt.wavedec(x,wf,level=7)\n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff.append(coeffs_flatten)\n",
    "    \n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(128))\n",
    "    # Apply Threshold on 4 last levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=3 else c for i,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    TCoeff.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff = np.array(Coeff)\n",
    "TCoeff = np.array(TCoeff)\n",
    "print(Coeff.shape, TCoeff.shape)\n",
    "print(np.sum(Coeff!=0), np.sum(TCoeff!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On conserve seulement les coefficients de niveau 1 à 4, les autres sont considérés comme du bruit et annulés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Coefficient de niveau 1 à 4 : \n",
    "CoeffA4=Coeff[:,:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP des coefficients d'ondelettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_ond = acp.fit_transform(sp.scale(Coeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_ond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_ond, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP des coefficients d'ondelettes de niveau 1 à 4 :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_ondA4 = acp.fit_transform(sp.scale(CoeffA4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_ondA4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markersizes = [60 if y==1 else 140 for y in Y]\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_ondA4, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ascendante hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(Coeff, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  One class SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur tous les coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(Coeff)\n",
    "pred = OCS.predict(Coeff)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats avec les coefficients seuillés ? Avec les coefficients de niveau 1 à 4 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur  les coefficients de niveaux 1 à 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(CoeffA4)\n",
    "\n",
    "CT_ond_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_ond_lof.pred, CT_ond_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_ond_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats avec les tous les coefficients ? avec les coefficients seuillés ? Avec les coefficients de niveau  plus élevé ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur tous les coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(Coeff)\n",
    "y_pred = clf.predict(Coeff)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Obtient-on de meilleurs résultats avec les coefficients seuillés ? Avec les coefficients de niveau 1 à 4 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Nous avons travaillé seulement sur l'accélération en x.  Considérer l'ensemble des signaux améliore-t-il les résultats ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :** Les méthodes de détection d'anomalies considérées appliquées sur  signaux bruts, comme les coefficinets d'ondelettes ne permettent pas de détecter les signaux atypiques. \n",
    "Nous allons utiliser la transformée de Fourier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection d'anomalies sur les coefficients de la FFT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients fft : \n",
    "\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "isignal = 0\n",
    "print(\" signal \" + SIGNALS[isignal])\n",
    "X_signal = np.vstack([x[:,isignal] for x in X])\n",
    "\n",
    "#print(amplitudefft)\n",
    "#plt.plot(amplitudefft)\n",
    "\n",
    "fftCoeff = []\n",
    "\n",
    "for x in X_signal :\n",
    "    \n",
    "    mx=np.mean(x)\n",
    "    x_centre=x-mx\n",
    "   #Apply fast Fourier transform\n",
    "    coeffsfft=np.abs(fft(x_centre))  \n",
    "    coeffsfft_flatten = np.hstack(coeffsfft)\n",
    "    fftCoeff.append(coeffsfft_flatten)\n",
    "        \n",
    "fftCoeff = np.array(fftCoeff)\n",
    "\n",
    "# Il suffit de garder la moitié des coefficients (ils sont ensuite répétés  de manière symétrique)\n",
    "\n",
    "fftCoeff=fftCoeff[:,:64]\n",
    "print(fftCoeff.shape)\n",
    "print(np.sum(fftCoeff!=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP des coefficients FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "X_acp_fft = acp.fit_transform(sp.scale(fftCoeff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_variance_acp(fig, acp, X_acp_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "uil.plot_projection_acp(fig, X_acp_fft, acp, colors, markersizes, color_dic=COLOR_DIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification ascendante hiérarchique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sch.linkage(fftCoeff, 'single')\n",
    "C = np.array([c[0] for c in sch.cut_tree(Z,6)])\n",
    "\n",
    "CT_HCA = pd.DataFrame(list(zip(C,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_HCA.pred, CT_HCA.Anomaly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"\" if y==\"WALKING\" else y for y in Y_label]\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "sch.dendrogram( Z, p=6, leaf_rotation=45.,leaf_font_size=15,labels=LABELS, truncate_mode=\"level\"  # font size for the x axis labels\n",
    ")\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "\n",
    "ax =fig.get_axes()[0]\n",
    "xlbls = ax.get_xmajorticklabels()\n",
    "for lbl in xlbls:\n",
    "    if lbl.get_text() in COLOR_DIC:\n",
    "        lbl.set_color(COLOR_DIC[lbl.get_text()])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(fftCoeff)\n",
    "pred = OCS.predict(fftCoeff)\n",
    "\n",
    "CT_FFT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_FFT_svm.pred, CT_FFT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contamination=0.05\n",
    "metric = \"euclidean\"\n",
    "n_neighbors = 15\n",
    "clf = sn.LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination, metric=metric)\n",
    "y_pred = clf.fit_predict(fftCoeff)\n",
    "\n",
    "CT_FFT_lof = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_FFT_lof.pred, CT_FFT_lof.Anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "uil.plot_detection_result(fig, ax, CT_FFT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = se.IsolationForest(n_estimators=100, contamination=0.05, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "clf.fit(fftCoeff)\n",
    "y_pred = clf.predict(fftCoeff)\n",
    "\n",
    "CT_IF = pd.DataFrame(list(zip(y_pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_IF.pred, CT_IF.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualisation des résultats de LOF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,40))\n",
    "ax = fig.add_subplot(3,2,1)\n",
    "uil.plot_detection_result(fig, ax, CT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Donnees Brutes- Boddy acc x \", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,2)\n",
    "uil.plot_detection_result(fig, ax, CT_tous_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Donnees Brutes- tous les signaux\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,3)\n",
    "uil.plot_detection_result(fig, ax, CT_ACP_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"ACP, 2 premieres composantes\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,4)\n",
    "uil.plot_detection_result(fig, ax, CT_ond_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Ondelettes, coefficients niveaux 1 à 4 \", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,5)\n",
    "uil.plot_detection_result(fig, ax, CT_metier_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"Données métiers\", fontsize=25)\n",
    "ax = fig.add_subplot(3,2,6)\n",
    "uil.plot_detection_result(fig, ax, CT_FFT_lof, COLOR_DIC, normal_behaviour=\"WALKING\")\n",
    "ax.set_title(\"FFT\", fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "954px",
    "left": "0px",
    "right": "1921.34px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
