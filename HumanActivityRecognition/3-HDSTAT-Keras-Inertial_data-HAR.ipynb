{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # [Apprentissage en Grande Dimension](https://github.com/wikistat/High-Dimensional-Learning ) : [Reconnaissance d'Activité Humaine](https://github.com/wikistat/High-Dimensional-Learning/tree/master/HumanActivityRecognition) ([*HAR*](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a>  Seconde partie:  apprentissage (profond) des signaux bruts  avec <a href=\"https://keras.io/\"><img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" style=\"max-width: 100px; display: inline\" alt=\"Keras\"/></a>\n",
    "\n",
    "Ce notebook présente la partie prediction de l'activité. Pour l'exploration, se référer au calepin afférent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Introduction\n",
    "##   Contexte\n",
    "Les données sont issues de la communauté qui vise la reconnaissance d'activités humaines (*Human activity recognition, HAR*) à partir d’enregistrements, par exemple du gyroscope et de l'accéléromètre d'un smartphone.\n",
    "Voir à ce propos l'[article](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-11.pdf) relatant un colloque de 2013.  \n",
    "\n",
    "Les données publiques disponibles ont été acquises, décrites et analysées par [Anguita et al. (2013)](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2013-84.pdf). Elles sont accessibles sur le [dépôt](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) de l'University California Irvine (UCI) consacré à l'apprentissage machine ainsi que sur le site *Kaggle*.\n",
    "\n",
    "L'archive contient les données brutes: accélérations en x, y, et z, chacun de 128 colonnes. D'autres fichiers en y soustrayant la gravité naturelle ainsi que les accélérations angulaires en x, y, et z, soit en tout 9 fichiers. Mais 6 utiles avec 6*128=768 mesures.\n",
    "\n",
    "Les méthodes d'apprentissage sont appliquées sur ces données brutes, sans calculs préliminaires de caractéristiques (*features*).\n",
    "\n",
    "##  Objectif\n",
    "Cette deuxième étape s'intéresse aux données brutes. Est-il possible d'économiser le travail préliminaire de définition des variables métier en utilisant, par exemple, un algorithme d'apprentissage profond sur les données brutes ou leur transformation en ondelettes ?\n",
    "\n",
    "**Objectif** Faire aussi bien (96% de bien classés) qu'avec les variables métier.\n",
    "\n",
    "##  Méthodes abordées : \n",
    "**Attention l'accès à un environnement *GPU* est très vivement conseillé voire indispensable.**\n",
    "- Modélisation, prévision de l'échantillon test par\n",
    "   - Régression logistique (`Scikit-learn`) sur signaux \"applatis\"\n",
    "   - Apprentissage profond en utilisant `Keras` \n",
    "       - MLP sur signaux \"applatis\"\n",
    "       - MLP sur signaux mutlidimensionels\n",
    "       - 1D Convolution\n",
    "       - 2D Convolution\n",
    "   - Validation Monte Carlo pour choisir le modèle\n",
    "   \n",
    "   \n",
    "- ** Extensions possibles  à ce travail: **\n",
    "\n",
    "    - Application des méthodes d'apprentissage classiques et de l'apprentissage profond sur les coefficients des décompositions des signaux en ondelettes\n",
    "    - Optimisation des paramètres des différentes méthodes.\n",
    "    - Améliorer l'architecture des réseaux ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Mise en place\n",
    "## Librairies et initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#Utils Sklearn\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "\n",
    "# DEEP LEARING\n",
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "# for reproducibility\n",
    "# https://github.com/fchollet/keras/issues/2280\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import tensorflow.keras.models as km \n",
    "import tensorflow.keras.layers as kl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "##  Prise en charge des données\n",
    "### Sources\n",
    "\n",
    "Les données sont celles originales du dépôt de l'[UCI](https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones). Elle peuvent être téléchargées en cliquant [ici](https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip).\n",
    "\n",
    "Elles contiennent deux jeux de dimensions différentes, chacun partagé en apprentissage et test.\n",
    "\n",
    "1. Multidimensionel: un individus est constitué de 9 Séries Temporelles de *dimensions* $(N, 128, 9)$\n",
    "2. Unidimensionnel: Les 9 Séries Temporelles sont concaténées pour constituer un vecteur de 128*9 = 1152 variables de *dimensions* $(N, 1152)*\n",
    "        \n",
    "Deux objets différents sont construits pour définir la variable $Y$ réponse car les librairies `Scikit-learn` et `Keras` prennent en compte des structures différentes: \n",
    "    \n",
    "1. `Scikit-Learn`  Un vecteur de dimension $(N, 1)$ avec, pour chaque individu le numéro du label de l'activité de 0 à 5.\n",
    "2. `Keras` Une matrice de dimension $(N, 6)$ des indicatrices (0 ou 1) des modalités de $Y$.\n",
    "\n",
    "### Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# attention: adapter si besoin le chemin d'accès aux données\n",
    "\n",
    "DATADIR_UCI = '.'\n",
    "SIGNALS = [ \"body_acc_x\", \"body_acc_y\", \"body_acc_z\", \"body_gyro_x\", \"body_gyro_y\", \"body_gyro_z\", \"total_acc_x\", \"total_acc_y\", \"total_acc_z\"]\n",
    "\n",
    "def my_read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "def load_signal(data_dir, subset, signal):\n",
    "    filename = f'{data_dir}/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "    x = my_read_csv(filename).as_matrix()\n",
    "    return x \n",
    "\n",
    "def load_signals(data_dir, subset, flatten = False):\n",
    "    signals_data = []\n",
    "    for signal in SIGNALS:\n",
    "        signals_data.append(load_signal(data_dir, subset, signal)) \n",
    "    \n",
    "    if flatten :\n",
    "        X = np.hstack(signals_data)\n",
    "    else:\n",
    "        X = np.transpose(signals_data, (1, 2, 0))\n",
    "        \n",
    "    return X \n",
    "\n",
    "def load_y(data_dir, subset, dummies = False):\n",
    "    filename = f'{data_dir}/{subset}/y_{subset}.txt'\n",
    "    y = my_read_csv(filename)[0]\n",
    "    \n",
    "    \n",
    "    if dummies:\n",
    "        Y = pd.get_dummies(y).as_matrix()\n",
    "    else:\n",
    "        Y = y.as_matrix()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérification des dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/DL/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/envs/DL/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/anaconda3/envs/DL/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "#Multidimensional Data\n",
    "X_train, X_test = load_signals(DATADIR_UCI, 'train'), load_signals(DATADIR_UCI, 'test')\n",
    "# Flattened Data\n",
    "X_train_flatten, X_test_flatten = load_signals(DATADIR_UCI, 'train', flatten=True), load_signals(DATADIR_UCI, 'test', flatten=True)\n",
    "\n",
    "# Label Y\n",
    "Y_train_label, Y_test_label = load_y(DATADIR_UCI, 'train', dummies = False), load_y(DATADIR_UCI, 'test', dummies = False)\n",
    "#Dummies Y (For Keras)\n",
    "Y_train_dummies, Y_test_dummies = load_y(DATADIR_UCI, 'train', dummies = True), load_y(DATADIR_UCI, 'test', dummies = True)\n",
    "\n",
    "N_train = X_train.shape[0]\n",
    "N_test = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension\n",
      "Données Multidimensionelles, : (7352, 128, 9)\n",
      "Données Unimensionelles, : (7352, 1152)\n",
      "Vecteur réponse (scikit-learn) : (7352,)\n",
      "Matrice réponse(Keras) : (7352, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimension\")\n",
    "print(\"Données Multidimensionelles, : \" + str(X_train.shape))\n",
    "print(\"Données Unimensionelles, : \" + str(X_train_flatten.shape))\n",
    "print(\"Vecteur réponse (scikit-learn) : \" + str(Y_train_label.shape))\n",
    "print(\"Matrice réponse(Keras) : \" + str(Y_train_dummies.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = [\"WALKING\",\"WALKING UPSTAIRS\",\"WALKING DOWNSTAIRS\",\"SITTING\",\"STANDING\",\"LAYING\"]\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "\n",
    "def my_confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])\n",
    "\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage des signaux uni-dimensionels\n",
    "\n",
    "La base d'apprentissage est de dimension (`N_train`, 1152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Régression Logistique\n",
    "\n",
    "La Régression Logistique est une des méthodes conduisant aux meilleurs résultats sur les variables métier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/DL/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/envs/DL/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Score With Logistic Regression on Inertial Signals = 57.45, Learning time = 26.60 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>LAYING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>120</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING UPSTAIRS</th>\n",
       "      <td>74</td>\n",
       "      <td>218</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING DOWNSTAIRS</th>\n",
       "      <td>92</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>79</td>\n",
       "      <td>32</td>\n",
       "      <td>58</td>\n",
       "      <td>397</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>131</td>\n",
       "      <td>92</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    WALKING  WALKING UPSTAIRS  WALKING DOWNSTAIRS  SITTING  \\\n",
       "WALKING                 120                63                  97        0   \n",
       "WALKING UPSTAIRS         74               218                  56       23   \n",
       "WALKING DOWNSTAIRS       92                66                 103        1   \n",
       "SITTING                  79                32                  58      397   \n",
       "STANDING                131                92                 106       70   \n",
       "LAYING                    0                 0                   0        0   \n",
       "\n",
       "                    STANDING  LAYING  \n",
       "WALKING                    1       0  \n",
       "WALKING UPSTAIRS          72      27  \n",
       "WALKING DOWNSTAIRS         2       0  \n",
       "SITTING                  112       0  \n",
       "STANDING                 345       0  \n",
       "LAYING                     0     510  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_lr = lm.LogisticRegression(verbose=1)\n",
    "model_lr.fit(X_train_flatten, Y_train_label)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "score = model_lr.score(X_test_flatten, Y_test_label)\n",
    "print(\"Score With Logistic Regression on Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "lr_prediction_label = model_lr.predict(X_test_flatten)\n",
    "metadata_svc = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "pd.DataFrame(confusion_matrix(lr_prediction_label, Y_test_label), index = LABELS, columns=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que dire de la performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron multicouche\n",
    "\n",
    "Un réseau de neurones classique est appris sur les données au même format que précédemment.\n",
    "\n",
    "**Q** Expliciter les choix des paramètres et donc la structure du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 37,094\n",
      "Trainable params: 37,094\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_hidden = 32\n",
    "\n",
    "n_features = X_train_flatten.shape[1]\n",
    "n_classes=6\n",
    "\n",
    "\n",
    "model_base_mlp_u =km.Sequential()\n",
    "model_base_mlp_u.add(kl.Dense(n_hidden, input_shape=(n_features,),  activation = \"relu\"))\n",
    "model_base_mlp_u.add(kl.Dropout(0.5))\n",
    "model_base_mlp_u.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_mlp_u.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model_base_mlp_u.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "WARNING:tensorflow:From /anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 1s 81us/sample - loss: 1.1852 - acc: 0.5193 - val_loss: 0.9812 - val_acc: 0.6871\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 0s 57us/sample - loss: 0.8903 - acc: 0.6753 - val_loss: 0.8015 - val_acc: 0.7570\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 0s 58us/sample - loss: 0.7772 - acc: 0.7197 - val_loss: 0.7000 - val_acc: 0.8069\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 0s 61us/sample - loss: 0.7176 - acc: 0.7365 - val_loss: 0.6793 - val_acc: 0.8022\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 0s 57us/sample - loss: 0.6646 - acc: 0.7580 - val_loss: 0.6111 - val_acc: 0.8171\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 0s 57us/sample - loss: 0.6490 - acc: 0.7626 - val_loss: 0.5832 - val_acc: 0.8246\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 0s 57us/sample - loss: 0.6378 - acc: 0.7636 - val_loss: 0.5838 - val_acc: 0.8317\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 0s 57us/sample - loss: 0.6138 - acc: 0.7761 - val_loss: 0.5935 - val_acc: 0.8215\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 0s 60us/sample - loss: 0.6005 - acc: 0.7805 - val_loss: 0.5776 - val_acc: 0.8283\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 0s 59us/sample - loss: 0.5669 - acc: 0.7919 - val_loss: 0.5699 - val_acc: 0.8331\n",
      "2947/2947 [==============================] - 0s 19us/sample - loss: 0.5699 - acc: 0.8331\n",
      "Score With Simple MLP on Inertial Signals = 83.31, Learning time = 4.75 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>435</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>416</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>357</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>68</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 537        0         0        0                   0   \n",
       "SITTING                  0      331       139        0                   3   \n",
       "STANDING                 0       67       435        2                   6   \n",
       "WALKING                  0       19         1      416                  50   \n",
       "WALKING_DOWNSTAIRS       0        3         6       14                 357   \n",
       "WALKING_UPSTAIRS         0        0         0       24                  68   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                             0  \n",
       "SITTING                           18  \n",
       "STANDING                          22  \n",
       "WALKING                           10  \n",
       "WALKING_DOWNSTAIRS                40  \n",
       "WALKING_UPSTAIRS                 379  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp_u.fit(X_train_flatten,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test_flatten, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp_u.evaluate(X_test_flatten, Y_test_dummies)[1] \n",
    "print(\"Score With Simple MLP on Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp_u = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_u_prediction = model_base_mlp_u.predict(X_test_flatten)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_u_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q ** : Que conclure sur ces résultats en terme de performance, de temps d'apprentissage? Comparer avec la regression logistique?\n",
    "\n",
    "** Exercice ** : Quelle est l'influence de l'ajout de nouvelle couche? Supression du Dropout? ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage des signaux multidimensionnels\n",
    "Les différents signaux ne sont pas concaténés en un seul signal mais pris en compte parallèlement.\n",
    "\n",
    "## Perceptron multichouche\n",
    "**Q** Expliciter les choix des paramètres et donc la structure du réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128, 50)           500       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 38406     \n",
      "=================================================================\n",
      "Total params: 38,906\n",
      "Trainable params: 38,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 50\n",
    "\n",
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "model_base_mlp =km.Sequential()\n",
    "model_base_mlp.add(kl.Dense(n_hidden, input_shape=(timesteps, input_dim),  activation = \"relu\"))\n",
    "model_base_mlp.add(kl.Reshape((timesteps*n_hidden,) , input_shape= (timesteps, n_hidden)  ))\n",
    "model_base_mlp.add(kl.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model_base_mlp.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_base_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 1s 95us/sample - loss: 0.5988 - acc: 0.7542 - val_loss: 0.6925 - val_acc: 0.7265\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 1s 76us/sample - loss: 0.3434 - acc: 0.8671 - val_loss: 0.7386 - val_acc: 0.7302\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 1s 74us/sample - loss: 0.2581 - acc: 0.9021 - val_loss: 0.6058 - val_acc: 0.8120\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 1s 88us/sample - loss: 0.2088 - acc: 0.9248 - val_loss: 0.5268 - val_acc: 0.8510\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 1s 75us/sample - loss: 0.1766 - acc: 0.9290 - val_loss: 0.5328 - val_acc: 0.8385\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 1s 87us/sample - loss: 0.1531 - acc: 0.9397 - val_loss: 0.5169 - val_acc: 0.8524\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 1s 83us/sample - loss: 0.1359 - acc: 0.9460 - val_loss: 0.5148 - val_acc: 0.8534\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 1s 89us/sample - loss: 0.1252 - acc: 0.9518 - val_loss: 0.5456 - val_acc: 0.8568\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 1s 76us/sample - loss: 0.1157 - acc: 0.9529 - val_loss: 0.5451 - val_acc: 0.8551\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 1s 81us/sample - loss: 0.1061 - acc: 0.9562 - val_loss: 0.5785 - val_acc: 0.8537\n",
      "2947/2947 [==============================] - 0s 26us/sample - loss: 0.5785 - acc: 0.8537\n",
      "Score With Simple MLP on Multidimensional Inertial Signals = 85.37, Learning time = 6.36 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>485</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 510        0         0        0                   0   \n",
       "SITTING                  0      333       133        1                   0   \n",
       "STANDING                 0       30       485        2                   0   \n",
       "WALKING                  0        0         0      422                  68   \n",
       "WALKING_DOWNSTAIRS       0        0         0       25                 395   \n",
       "WALKING_UPSTAIRS         0        0         0       81                  19   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                            27  \n",
       "SITTING                           24  \n",
       "STANDING                          15  \n",
       "WALKING                            6  \n",
       "WALKING_DOWNSTAIRS                 0  \n",
       "WALKING_UPSTAIRS                 371  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_mlp.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_mlp.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"Score With Simple MLP on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_mlp = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_mlp_prediction = model_base_mlp.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_mlp_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau avec couche convolutionelle 1D (*ConvNet*)\n",
    "\n",
    "L'idée pertinente avec ces données est évidemment d'identifier le problème lié au déphasage des signaux. L'utilisation d'une couche convolutionnelle introduit une propriété d'invariance par translation. Les caractéristiques ou *features* sortant de cette couche acquièrent donc ainsi de bonnes propriétés avant d'être dirigées vers des couches techniques intermédiaires (`MaxPooling, Flatten`) et une dernière couche de sortie qui effectue la discrimination à partir des caractéristiques.\n",
    "\n",
    "**Q.** Remarquer le nombre de paramètres à estimer, le comparer avec celui du perceptron précédent et comprendre comment la convolution 1D agit sur les signaux (regarder en particulier la forme de la sortie de chaque couche du réseau). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 120, 32)           2624      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 40, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 7686      \n",
      "=================================================================\n",
      "Total params: 10,310\n",
      "Trainable params: 10,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "#else:\n",
    "model_base_conv_1D =km.Sequential()\n",
    "model_base_conv_1D.add(kl.Conv1D(32, 9, activation='relu', input_shape=(timesteps, input_dim)))\n",
    "model_base_conv_1D.add(kl.MaxPooling1D(pool_size=3))\n",
    "model_base_conv_1D.add(kl.Flatten())\n",
    "model_base_conv_1D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_1D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_base_conv_1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 1s 157us/sample - loss: 0.5235 - acc: 0.8105 - val_loss: 0.4992 - val_acc: 0.8107\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 1s 128us/sample - loss: 0.1829 - acc: 0.9368 - val_loss: 0.3169 - val_acc: 0.8965\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 1s 127us/sample - loss: 0.1299 - acc: 0.9494 - val_loss: 0.2873 - val_acc: 0.9046\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 1s 129us/sample - loss: 0.1126 - acc: 0.9521 - val_loss: 0.2645 - val_acc: 0.9125\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 1s 127us/sample - loss: 0.1063 - acc: 0.9569 - val_loss: 0.2541 - val_acc: 0.9203\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 1s 121us/sample - loss: 0.1035 - acc: 0.9558 - val_loss: 0.2539 - val_acc: 0.9240\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 1s 127us/sample - loss: 0.0978 - acc: 0.9582 - val_loss: 0.2428 - val_acc: 0.9294\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 1s 135us/sample - loss: 0.0943 - acc: 0.9615 - val_loss: 0.2699 - val_acc: 0.9359\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 1s 132us/sample - loss: 0.0911 - acc: 0.9627 - val_loss: 0.2522 - val_acc: 0.9376\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 1s 133us/sample - loss: 0.0875 - acc: 0.9641 - val_loss: 0.2554 - val_acc: 0.9274\n",
      "2947/2947 [==============================] - 0s 45us/sample - loss: 0.2554 - acc: 0.9274\n",
      "Score With Conv on Multidimensional Inertial Signals = 92.74, Learning time = 10.03 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>4</td>\n",
       "      <td>369</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>412</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 536        0         0        0                   0   \n",
       "SITTING                  4      369       111        0                   0   \n",
       "STANDING                 0       52       479        0                   0   \n",
       "WALKING                  0        0         0      489                   6   \n",
       "WALKING_DOWNSTAIRS       0        0         0        3                 412   \n",
       "WALKING_UPSTAIRS         0        0         0        2                  21   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                             1  \n",
       "SITTING                            7  \n",
       "STANDING                           1  \n",
       "WALKING                            1  \n",
       "WALKING_DOWNSTAIRS                 5  \n",
       "WALKING_UPSTAIRS                 448  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_conv_1D.fit(X_train,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_1D.evaluate(X_test, Y_test_dummies)[1] \n",
    "print(\"Score With Conv on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_1D_prediction = model_base_conv_1D.predict(X_test)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_conv_1D_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau avec couche convolutionelle 2D (*ConvNet*)\n",
    "\n",
    "**Q.** Remarquer le nombre de paramètres à estimer, le comparer avec celui du réseau précédent et comprendre comment la convolution 2D agit sur les signaux (regarder en particulier la forme de la sortie de chaque couche du réseau). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 1, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 12102     \n",
      "=================================================================\n",
      "Total params: 12,998\n",
      "Trainable params: 12,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = 6\n",
    "\n",
    "X_train_conv = X_train.reshape(N_train, timesteps, input_dim, 1)\n",
    "X_test_conv = X_test.reshape(N_test, timesteps, input_dim, 1)\n",
    "\n",
    "#else:\n",
    "model_base_conv_2D =km.Sequential()\n",
    "model_base_conv_2D.add(kl.Conv2D(32, (3, 9), activation='relu', input_shape=(timesteps, input_dim, 1)))\n",
    "model_base_conv_2D.add(kl.MaxPooling2D(pool_size=(2, 1)))\n",
    "model_base_conv_2D.add(kl.Flatten())\n",
    "model_base_conv_2D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "model_base_conv_2D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model_base_conv_2D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/10\n",
      "7352/7352 [==============================] - 1s 156us/sample - loss: 0.6526 - acc: 0.7522 - val_loss: 0.6477 - val_acc: 0.7316\n",
      "Epoch 2/10\n",
      "7352/7352 [==============================] - 1s 131us/sample - loss: 0.3436 - acc: 0.8731 - val_loss: 0.5188 - val_acc: 0.8212\n",
      "Epoch 3/10\n",
      "7352/7352 [==============================] - 1s 130us/sample - loss: 0.2485 - acc: 0.9142 - val_loss: 0.4465 - val_acc: 0.8473\n",
      "Epoch 4/10\n",
      "7352/7352 [==============================] - 1s 128us/sample - loss: 0.1970 - acc: 0.9282 - val_loss: 0.4236 - val_acc: 0.8724\n",
      "Epoch 5/10\n",
      "7352/7352 [==============================] - 1s 127us/sample - loss: 0.1709 - acc: 0.9380 - val_loss: 0.3949 - val_acc: 0.8717\n",
      "Epoch 6/10\n",
      "7352/7352 [==============================] - 1s 139us/sample - loss: 0.1527 - acc: 0.9416 - val_loss: 0.3735 - val_acc: 0.8680\n",
      "Epoch 7/10\n",
      "7352/7352 [==============================] - 1s 128us/sample - loss: 0.1409 - acc: 0.9471 - val_loss: 0.3530 - val_acc: 0.8823\n",
      "Epoch 8/10\n",
      "7352/7352 [==============================] - 1s 128us/sample - loss: 0.1313 - acc: 0.9487 - val_loss: 0.3389 - val_acc: 0.8765\n",
      "Epoch 9/10\n",
      "7352/7352 [==============================] - 1s 120us/sample - loss: 0.1245 - acc: 0.9527 - val_loss: 0.3505 - val_acc: 0.8799\n",
      "Epoch 10/10\n",
      "7352/7352 [==============================] - 1s 129us/sample - loss: 0.1186 - acc: 0.9536 - val_loss: 0.3536 - val_acc: 0.8819\n",
      "2947/2947 [==============================] - 0s 52us/sample - loss: 0.3536 - acc: 0.8819\n",
      "Score With Conv on Multidimensional Inertial Signals = 88.19, Learning time = 10.03 secondes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>75</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>407</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
       "True                                                                         \n",
       "LAYING                 537        0         0        0                   0   \n",
       "SITTING                  0      375       106        0                   0   \n",
       "STANDING                 0       79       452        0                   0   \n",
       "WALKING                  0        0         0      404                  75   \n",
       "WALKING_DOWNSTAIRS       0        0         0        8                 407   \n",
       "WALKING_UPSTAIRS         0        0         0        3                  44   \n",
       "\n",
       "Pred                WALKING_UPSTAIRS  \n",
       "True                                  \n",
       "LAYING                             0  \n",
       "SITTING                           10  \n",
       "STANDING                           1  \n",
       "WALKING                           17  \n",
       "WALKING_DOWNSTAIRS                 5  \n",
       "WALKING_UPSTAIRS                 424  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "model_base_conv_2D.fit(X_train_conv,  Y_train_dummies, batch_size=batch_size, validation_data=(X_test_conv, Y_test_dummies), epochs=epochs)\n",
    "t_end = time.time()\n",
    "t_learning = t_end-t_start\n",
    "\n",
    "score = model_base_conv_2D.evaluate(X_test_conv, Y_test_dummies)[1] \n",
    "print(\"Score With Conv on Multidimensional Inertial Signals = %.2f, Learning time = %.2f secondes\" %(score*100, t_learning) )\n",
    "metadata_conv = {\"time_learning\" : t_learning, \"score\" : score}\n",
    "base_conv_2D_prediction = model_base_conv_2D.predict(X_test_conv)\n",
    "\n",
    "my_confusion_matrix(Y_test_dummies, base_conv_2D_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Attention au sur-apprentissage** A force de rechercher la meilleure architecture en minimisant l'erreur sur l'échantillon test, celle finalement trouvée peut y être très adaptée réduisant ainsi la capacité de généralisation. Il serait prudent de multiplier le découpage de l'échantillon par validation croisée *Monte Carlo*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation de la Validation Croisée Monte Carlo\n",
    "\n",
    "**Objectif** :  trouver la meilleure architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.copy(np.concatenate((X_train, X_test), axis=0))\n",
    "Y=np.copy(np.concatenate((Y_train_dummies, Y_test_dummies), axis=0))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "#Il faudrait en prendre plus ..\n",
    "batch_size = 32\n",
    "n_hidden = 32\n",
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ***************** 0 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 77us/sample - loss: 0.6300 - acc: 0.7418 - val_loss: 0.4933 - val_acc: 0.7961\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 125us/sample - loss: 0.5112 - acc: 0.8182 - val_loss: 0.2351 - val_acc: 0.9146\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 128us/sample - loss: 0.6461 - acc: 0.7497 - val_loss: 0.4067 - val_acc: 0.8573\n",
      "2060/2060 [==============================] - 0s 19us/sample - loss: 0.4933 - acc: 0.7961\n",
      "2060/2060 [==============================] - 0s 35us/sample - loss: 0.2351 - acc: 0.9146\n",
      "2060/2060 [==============================] - 0s 34us/sample - loss: 0.4067 - acc: 0.8573\n",
      "\n",
      " \n",
      " ***************** 1 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 86us/sample - loss: 0.6397 - acc: 0.7332 - val_loss: 0.4770 - val_acc: 0.8194\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 130us/sample - loss: 0.5721 - acc: 0.7810 - val_loss: 0.3253 - val_acc: 0.8767\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 130us/sample - loss: 0.6753 - acc: 0.7293 - val_loss: 0.4958 - val_acc: 0.8083\n",
      "2060/2060 [==============================] - 0s 21us/sample - loss: 0.4770 - acc: 0.8194\n",
      "2060/2060 [==============================] - 0s 38us/sample - loss: 0.3253 - acc: 0.8767\n",
      "2060/2060 [==============================] - 0s 36us/sample - loss: 0.4958 - acc: 0.8083\n",
      "\n",
      " \n",
      " ***************** 2 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 86us/sample - loss: 0.6254 - acc: 0.7449 - val_loss: 0.4810 - val_acc: 0.8092\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 137us/sample - loss: 0.5729 - acc: 0.7796 - val_loss: 0.2968 - val_acc: 0.8947\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 133us/sample - loss: 0.6771 - acc: 0.7388 - val_loss: 0.4394 - val_acc: 0.8432\n",
      "2060/2060 [==============================] - 0s 22us/sample - loss: 0.4810 - acc: 0.8092\n",
      "2060/2060 [==============================] - 0s 40us/sample - loss: 0.2968 - acc: 0.8947\n",
      "2060/2060 [==============================] - 0s 39us/sample - loss: 0.4394 - acc: 0.8432\n",
      "\n",
      " \n",
      " ***************** 3 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 90us/sample - loss: 0.6026 - acc: 0.7632 - val_loss: 0.4279 - val_acc: 0.8364\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 154us/sample - loss: 0.5480 - acc: 0.7997 - val_loss: 0.2848 - val_acc: 0.8898\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 174us/sample - loss: 0.6537 - acc: 0.7424 - val_loss: 0.4370 - val_acc: 0.8524\n",
      "2060/2060 [==============================] - 0s 25us/sample - loss: 0.4279 - acc: 0.8364\n",
      "2060/2060 [==============================] - 0s 48us/sample - loss: 0.2848 - acc: 0.8898\n",
      "2060/2060 [==============================] - 0s 42us/sample - loss: 0.4370 - acc: 0.8524\n",
      "\n",
      " \n",
      " ***************** 4 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 115us/sample - loss: 0.6596 - acc: 0.7214 - val_loss: 0.4790 - val_acc: 0.8083\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 171us/sample - loss: 0.5595 - acc: 0.7859 - val_loss: 0.3146 - val_acc: 0.9024\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 152us/sample - loss: 0.6354 - acc: 0.7604 - val_loss: 0.4053 - val_acc: 0.8330\n",
      "2060/2060 [==============================] - 0s 22us/sample - loss: 0.4790 - acc: 0.8083\n",
      "2060/2060 [==============================] - 0s 41us/sample - loss: 0.3146 - acc: 0.9024\n",
      "2060/2060 [==============================] - 0s 40us/sample - loss: 0.4053 - acc: 0.8330\n",
      "\n",
      " \n",
      " ***************** 5 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 99us/sample - loss: 0.6420 - acc: 0.7392 - val_loss: 0.4475 - val_acc: 0.7981\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 162us/sample - loss: 0.5539 - acc: 0.7894 - val_loss: 0.3130 - val_acc: 0.8816\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 172us/sample - loss: 0.6680 - acc: 0.7355 - val_loss: 0.4148 - val_acc: 0.8500\n",
      "2060/2060 [==============================] - 0s 22us/sample - loss: 0.4475 - acc: 0.7981\n",
      "2060/2060 [==============================] - 0s 40us/sample - loss: 0.3130 - acc: 0.8816\n",
      "2060/2060 [==============================] - 0s 45us/sample - loss: 0.4148 - acc: 0.8500\n",
      "\n",
      " \n",
      " ***************** 6 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 131us/sample - loss: 0.6235 - acc: 0.7386 - val_loss: 0.4641 - val_acc: 0.8121\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 173us/sample - loss: 0.5488 - acc: 0.7963 - val_loss: 0.2867 - val_acc: 0.9010\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 173us/sample - loss: 0.6748 - acc: 0.7329 - val_loss: 0.4545 - val_acc: 0.8204\n",
      "2060/2060 [==============================] - 0s 24us/sample - loss: 0.4641 - acc: 0.8121\n",
      "2060/2060 [==============================] - 0s 43us/sample - loss: 0.2867 - acc: 0.9010\n",
      "2060/2060 [==============================] - 0s 47us/sample - loss: 0.4545 - acc: 0.8204\n",
      "\n",
      " \n",
      " ***************** 7 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 121us/sample - loss: 0.6289 - acc: 0.7363 - val_loss: 0.4871 - val_acc: 0.8049\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 176us/sample - loss: 0.5454 - acc: 0.7931 - val_loss: 0.2845 - val_acc: 0.8981\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 178us/sample - loss: 0.6462 - acc: 0.7525 - val_loss: 0.4133 - val_acc: 0.8490\n",
      "2060/2060 [==============================] - 0s 23us/sample - loss: 0.4871 - acc: 0.8049\n",
      "2060/2060 [==============================] - 0s 44us/sample - loss: 0.2845 - acc: 0.8981\n",
      "2060/2060 [==============================] - 0s 47us/sample - loss: 0.4133 - acc: 0.8490\n",
      "\n",
      " \n",
      " ***************** 8 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 125us/sample - loss: 0.6290 - acc: 0.7369 - val_loss: 0.4527 - val_acc: 0.8126\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 180us/sample - loss: 0.5408 - acc: 0.7972 - val_loss: 0.3032 - val_acc: 0.8835\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 2s 183us/sample - loss: 0.6546 - acc: 0.7337 - val_loss: 0.4312 - val_acc: 0.8398\n",
      "2060/2060 [==============================] - 0s 28us/sample - loss: 0.4527 - acc: 0.8126\n",
      "2060/2060 [==============================] - 0s 52us/sample - loss: 0.3032 - acc: 0.8835\n",
      "2060/2060 [==============================] - 0s 47us/sample - loss: 0.4312 - acc: 0.8398\n",
      "\n",
      " \n",
      " ***************** 9 ***************** \n",
      "\n",
      "\n",
      " **** MLP **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 1s 128us/sample - loss: 0.6551 - acc: 0.7289 - val_loss: 0.5064 - val_acc: 0.7762\n",
      "\n",
      " **** conv 1D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 2s 184us/sample - loss: 0.5310 - acc: 0.8091 - val_loss: 0.2663 - val_acc: 0.9170\n",
      "\n",
      " **** conv 2D **** \n",
      "\n",
      "Train on 8239 samples, validate on 2060 samples\n",
      "8239/8239 [==============================] - 2s 186us/sample - loss: 0.6459 - acc: 0.7480 - val_loss: 0.4128 - val_acc: 0.8345\n",
      "2060/2060 [==============================] - 0s 25us/sample - loss: 0.5064 - acc: 0.7762\n",
      "2060/2060 [==============================] - 0s 46us/sample - loss: 0.2663 - acc: 0.9170\n",
      "2060/2060 [==============================] - 0s 46us/sample - loss: 0.4128 - acc: 0.8345\n",
      "\n",
      " [[0.79611653 0.91456312 0.85728157]\n",
      " [0.81941748 0.87669903 0.80825245]\n",
      " [0.80922329 0.89466017 0.8432039 ]\n",
      " [0.83640778 0.88980585 0.85242718]\n",
      " [0.80825245 0.9024272  0.83300972]\n",
      " [0.79805827 0.88155341 0.85000002]\n",
      " [0.81213593 0.90097088 0.82038838]\n",
      " [0.80485439 0.89805824 0.84902912]\n",
      " [0.81262136 0.88349515 0.83980584]\n",
      " [0.77621359 0.91699028 0.83446604]]\n",
      "[80.73301077 89.5922333  83.87864232]\n"
     ]
    }
   ],
   "source": [
    "N_MC=10\n",
    "\n",
    "score=np.empty([N_MC,3])\n",
    "\n",
    "\n",
    "for k in range(N_MC):\n",
    "    print(\"\\n \\n *****************\",k,\"***************** \\n\")\n",
    "    X_train_MC,X_test_MC,Y_train_dummies_MC,Y_test_dummies_MC=train_test_split(X,Y,test_size=0.2)\n",
    "    N_train_MC = X_train_MC.shape[0]\n",
    "    N_test_MC = X_test_MC.shape[0]\n",
    "    \n",
    "    timesteps = len(X_train_MC[0])\n",
    "    input_dim = len(X_train_MC[0][0])\n",
    "    \n",
    "    X_train_conv_MC = X_train_MC.reshape(N_train_MC, timesteps, input_dim, 1)\n",
    "    X_test_conv_MC = X_test_MC.reshape(N_test_MC, timesteps, input_dim, 1)\n",
    "    \n",
    "    \n",
    "    # définition des modèles \n",
    "    model_base_mlp =km.Sequential()\n",
    "    model_base_mlp.add(kl.Dense(n_hidden, input_shape=(timesteps, input_dim),  activation = \"relu\"))\n",
    "    model_base_mlp.add(kl.Reshape((timesteps*n_hidden,) , input_shape= (timesteps, n_hidden)  ))\n",
    "    model_base_mlp.add(kl.Dense(n_classes, activation='softmax'))\n",
    "    model_base_mlp.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    model_base_conv_1D =km.Sequential()\n",
    "    model_base_conv_1D.add(kl.Conv1D(32, 9, activation='relu', input_shape=(timesteps, input_dim)))\n",
    "    model_base_conv_1D.add(kl.MaxPooling1D(pool_size=3))\n",
    "    model_base_conv_1D.add(kl.Flatten())\n",
    "    model_base_conv_1D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "    model_base_conv_1D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    model_base_conv_2D =km.Sequential()\n",
    "    model_base_conv_2D.add(kl.Conv2D(32, (3, 9), activation='relu', input_shape=(timesteps, input_dim, 1)))\n",
    "    model_base_conv_2D.add(kl.MaxPooling2D(pool_size=(2, 1)))\n",
    "    model_base_conv_2D.add(kl.Flatten())\n",
    "    model_base_conv_2D.add(kl.Dense(n_classes, activation='softmax'))\n",
    "    model_base_conv_2D.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "   \n",
    "    print(\"\\n **** MLP **** \\n\")\n",
    "    model_base_mlp.fit(X_train_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_MC, Y_test_dummies_MC), epochs=epochs)   \n",
    "\n",
    "    print(\"\\n **** conv 1D **** \\n\")\n",
    "    model_base_conv_1D.fit(X_train_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_MC, Y_test_dummies_MC), epochs=epochs)\n",
    "   \n",
    "    print(\"\\n **** conv 2D **** \\n\")\n",
    "    model_base_conv_2D.fit(X_train_conv_MC,  Y_train_dummies_MC, batch_size=batch_size, validation_data=(X_test_conv_MC, Y_test_dummies_MC), epochs=epochs)\n",
    "    \n",
    "    score_mlp=model_base_mlp.evaluate(X_test_MC, Y_test_dummies_MC)[1]\n",
    "    #score_lstm=model_base_lstm.evaluate(X_test_MC, Y_test_dummies_MC)[1]\n",
    "    score_conv_1D=model_base_conv_1D.evaluate(X_test_MC, Y_test_dummies_MC)[1]\n",
    "    score_conv_2D=model_base_conv_2D.evaluate(X_test_conv_MC, Y_test_dummies_MC)[1]\n",
    "    s=[score_mlp,score_conv_1D,score_conv_2D]\n",
    "    score[k,:]=s\n",
    "    \n",
    "final_scores=np.apply_along_axis(np.mean,0,score)*100\n",
    "print(\"\\n\",score)\n",
    "print(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP     : 80.73 % \n",
      "\n",
      "Conv 1D : 89.59 % \n",
      "\n",
      "Conv 2D : 83.88 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"MLP     :\",round(final_scores[0],2),\"% \\n\")\n",
    "print(\"Conv 1D :\",round(final_scores[1],2),\"% \\n\")\n",
    "print(\"Conv 2D :\",round(final_scores[2],2),\"% \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.** Quelle méthode est la plus performante ? Commenter ces résultats par rapport à ceux qui ont été obtenus sur les données \"métier\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
