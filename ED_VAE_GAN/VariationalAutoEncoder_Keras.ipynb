{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dimensional & Deep Learning : Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variational autoencoder is an autoencoder that learns a latent variable model for its input data.\n",
    "\n",
    "\n",
    "What is a variational autoencoder, you ask? It's a type of autoencoder with added constraints on the encoded representations being learned. More precisely, it is an autoencoder that learns a latent variable model for its input data. So instead of letting your neural network learn an arbitrary function, you are learning the parameters of a probability distribution modeling your data. If you sample points from this distribution, you can generate new input data samples: a VAE is a \"generative model\".\n",
    "\n",
    "How does a variational autoencoder work?\n",
    "\n",
    "First, an encoder network turns the input samples x into two parameters in a latent space, which we will note z_mean and z_log_sigma. Then, we randomly sample similar points z from the latent normal distribution that is assumed to generate the data, via z = z_mean + exp(z_log_sigma) * epsilon, where epsilon is a random normal tensor. Finally, a decoder network maps these latent space points back to the original input data.\n",
    "\n",
    "The parameters of the model are trained via two loss functions: a reconstruction loss forcing the decoded samples to match the initial inputs (just like in our previous autoencoders), and the KL divergence between the learned latent distribution and the prior distribution, acting as a regularization term. You could actually get rid of this latter term entirely, although it does help in learning well-formed latent spaces and reducing overfitting to the training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a simple Variational Auto Encoder\n",
    "* Use the Keras Model APi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.preprocessing.image as kpi\n",
    "import tensorflow.keras.models as km\n",
    "import tensorflow.keras.layers as kl\n",
    "import tensorflow.keras.losses as kloss\n",
    "import tensorflow.keras.regularizers as kr\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.utils as ku\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "input_dim = np.prod(x_train.shape[1:])\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]\n",
    "x_train = x_train.reshape((n_train, input_dim))\n",
    "x_test = x_test.reshape((n_test, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous TP on image classification of the autoencoder notebook we have used the `Sequential` method to build model.\n",
    "\n",
    "Sequential Method have limits when the architecture we want is not *linear* or when we want to build a layer on top on two different entries.\n",
    "\n",
    "The `Model` API can sometimes be less intuitive but is much more flexible than the `Sequential` method. We will use it all along this TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "\n",
    "batch_size=100\n",
    "intermediate_dim = 512\n",
    "latent_dim = 2\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO add image here. <br>\n",
    "TODO explain why log_var. <br>\n",
    "We first build the encoder part. <br>\n",
    "It is first composed of  a `Dense` layer with 512 neurons. <br>\n",
    "Two `Dense` layer are then added on **top of the same layer**. These two layers will produce the two variable *z_mean* and  *z_log_var* in the latent space.\n",
    "\n",
    "Note that we define each layer as a function of an input which is the output of the layer he follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# build encoder model\n",
    "inputs = kl.Input(shape=(784,), name='encoder_input')\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = kl.Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = kl.Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Â The stochastic latent variable\n",
    "\n",
    "We use the reparametrization trick to define a random variable z that is conditioned on the input image x as follows:\n",
    "\n",
    "$$ z \\sim \\mathcal{N}(\\mu_z(x), \\sigma_z(x)) $$\n",
    "\n",
    "<img src=\"image/vae_3.svg\" width=\"600px\" />\n",
    "\n",
    "\n",
    "\n",
    "The reparametrization tricks defines $z$ has follows:\n",
    "\n",
    "$$ z = \\mu_z(x) + \\sigma_z(x) \\cdot \\epsilon$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$ \\epsilon \\sim \\mathcal{N}(0, 1) $$\n",
    "\n",
    "This way the dependency to between $z$ and $x$ is deterministic and differentiable. The randomness of $z$ only stems from $\\epsilon$ only for a given $x$.\n",
    "\n",
    "Note that in practice the output of the encoder network parameterizes $log(\\sigma^2_z(x)$ instead of $\\sigma_z(x)$. Taking the exponential of $log(\\sigma^2_z(x)$ ensures the positivity of the standard deviation from the raw output of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = kl.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have defined all the layer we need to build the encoder part of the vae. <br> \n",
    "We now define the model, with the `Model`method. For that we just have to specify the input layer and the output we want (here, it's the latent variable z). The model is then build automatically.\n",
    "\n",
    "TODO allow plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          401920      encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            1026        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            1026        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (100, 2)             0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 403,972\n",
      "Trainable params: 403,972\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder model\n",
    "\n",
    "encoder = km.Model(inputs, z, name='encoder')\n",
    "encoder.summary()\n",
    "#ku.plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder \n",
    "\n",
    "The decoder take as an input the a vector z (which is a sample of the latent distribution define by the encoder). \n",
    "it is then compose of 2 Dense layers with the following caracteristics : \n",
    "\n",
    "* 512 neurons, relu activation\n",
    "* 784 neurons (input_shape), sigmoid activation\n",
    "\n",
    "**Exercise** build this simple model using the Model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/decoder_vae.py\n",
    "# build decoder model\n",
    "latent_inputs = kl.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = kl.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = kl.Dense(784, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = km.Model(latent_inputs, outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 403,728\n",
      "Trainable params: 403,728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()\n",
    "#plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True) TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vae\n",
    "\n",
    "We now associate the two model to define our Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (100, 2)                  403972    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              multiple                  403728    \n",
      "=================================================================\n",
      "Total params: 807,700\n",
      "Trainable params: 807,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs))\n",
    "vae = km.Model(inputs, outputs, name='vae_mlp')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"decoder\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"decoder\".\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (100, 2)                  403972    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              multiple                  403728    \n",
      "=================================================================\n",
      "Total params: 807,700\n",
      "Trainable params: 807,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reconstruction_loss = kloss.binary_crossentropy(inputs,\n",
    "                                              outputs)\n",
    "\n",
    "reconstruction_loss *= 784\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /anaconda3/envs/DL/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 189.7898 - val_loss: 168.9534\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 8s 134us/sample - loss: 165.5808 - val_loss: 163.2383\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 161.7854 - val_loss: 160.7026\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 159.5383 - val_loss: 158.9314\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 157.6584 - val_loss: 156.9970\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 156.0020 - val_loss: 155.7725\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 154.5752 - val_loss: 154.4151\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 153.4234 - val_loss: 153.6388\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 152.4663 - val_loss: 152.6056\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 11s 187us/sample - loss: 151.6020 - val_loss: 152.0075\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 150.8866 - val_loss: 151.6454\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 150.2630 - val_loss: 151.1499\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 11s 185us/sample - loss: 149.6960 - val_loss: 150.8712\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 11s 181us/sample - loss: 149.2105 - val_loss: 150.4867\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 12s 195us/sample - loss: 148.7560 - val_loss: 150.1757\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 148.3374 - val_loss: 149.8677\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 11s 181us/sample - loss: 147.9292 - val_loss: 149.5295\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 11s 185us/sample - loss: 147.6116 - val_loss: 149.4718\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 147.2216 - val_loss: 149.3113\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 12s 193us/sample - loss: 146.9738 - val_loss: 149.1201\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 11s 185us/sample - loss: 146.7047 - val_loss: 148.6664\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 11s 191us/sample - loss: 146.4600 - val_loss: 148.5770\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 11s 178us/sample - loss: 146.2304 - val_loss: 148.6536\n",
      "Epoch 24/50\n",
      " 6600/60000 [==>...........................] - ETA: 8s - loss: 145.7813"
     ]
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(x_test, None))\n",
    "vae.save_weights('vae_mlp_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of latent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap=\"Set1\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 2D manifold of the digits\n",
    "n = 15  # figure with 15x15 digits\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "# we will sample n points within [-15, 15] standard deviations\n",
    "grid_x = np.linspace(-15, 15, n)\n",
    "grid_y = np.linspace(-15, 15, n)\n",
    "\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
